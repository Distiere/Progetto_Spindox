# Progetto_Spindox
Pipeline per approfondimento e contesto di data engineer

# Analisi esplorativa ed ingestione dei dati in DB
Una prima parte del lavoro è stata quella di esplorare il dataset per controllare che le domande di business potessero avere risposta. Il problema maggiore riscontrato è stato quello dell'utilizzo di nuove librerie e grande varietà e confusione nel tipo di dato. Dopo un primo approccio di trial and error per tentare di fare già una prima pulizia del dato vista la grande mole di dati si è deciso per avere una totale conversione dei dati in stringa in modo da consultare gli attributi del dataset e confermare come le domande di business siano tutte abbordabili con i dati in nostro possesso mantenenendo comunque una fedeltà assoluta ai dati forniti. Si è quindi proseguito alla ingestione del dato su db finendo con un check che ha confermato la presenza dei dati e della ingestione stessa. Potendo quindi passare ora al Silver layer.

# Implementazione di tabelle clean utilizzabili
Una volta ingeriti i dati raw si è passata ad una analisi estensiva del dato decidendo in base alle colonne disponibili quali fossero da tenere e quali invece da scartare. Notato come una diretta trasposizione da bronze a silver non ha fatto perdere integrità del dato sono passato a standardizzare tutti i dati disponiili rendendo possibile la creazione delle metriche temporali necessarie a calcolare le KPI predisposte. Una volta fatto tutto ciò prima di creare le tabelle definitive per i due CSV sono andate a fare un parsing dei timestamp in modo da avere uniformità per la futura interrogazione delle tabelle. Infine visto l'irrisorio numero di valori negativi o impossibili per quanto riguarda metriche temporali (118 su 4 milioni di record) li ho attribuiti ad errore umano e quindi sostituiti con valori nulli. Create quindi le tabelle definitive passo al mock-up di   quello che andrò a fare ed alla implementazione del gold layer

# Mock up dashboard ed iniziazione ad implementazione gold layer
Avuta una stabilità nel silver layer che viene bloccato in caso ci siano delle incongruenze del dato da parte del bronze sono passato ad uno studio delle librerie di streamlit che col supporto della libreria di matplot avrebbe dovuto creare la dashboard mock uo basata sul silver per essere sicuro del suo funzionamento una volta implementato il gold. Ho riscontrato delle problematiche relative più che altro all'utilizzo di streamlit non essendone pratico. Consultata la documentazione ed implementate le query necessarie ho dovuto risolvere la problematica relativa ad un primo errore di creazione db che non era stato creato in cartella di data ma in root.

